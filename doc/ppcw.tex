\documentclass[twoside,11pt]{article}
\PassOptionsToPackage{hyphens}{url}
\usepackage{jmlr2e}
\usepackage{amsmath}
\usepackage[toc,page]{appendix}
\usepackage[table]{xcolor}
\usepackage[marginparsep=30pt]{geometry}
\usepackage{stmaryrd}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{tabu}
\usepackage{longtable}
\usepackage{tabularx}
\usepackage{listings}
\usepackage{fancyref}
\usepackage{relsize}
\usepackage{float}
\usepackage{subcaption}
\usepackage{diagbox}

\usetikzlibrary{%
    arrows,
    arrows.meta,
    decorations,
    backgrounds,
    positioning,
    fit,
    petri,
    shadows,
    datavisualization.formats.functions,
    calc,
    shapes,
    shapes.multipart,
    matrix,
    plotmarks
}

\usepgfplotslibrary{fillbetween, statistics}

\pgfplotsset{
  compat=1.3,
  every non boxed x axis/.style={
  enlarge x limits=false,
  x axis line style={}%-stealth},
  },
  every boxed x axis/.style={},
  every non boxed y axis/.style={
  enlarge y limits=false,
  y axis line style={}%-stealth},
  },
  every boxed y axis/.style={},
}

\def\perc{\texttt{perco\-late}}
\def\v{\texttt{v0.1.0}}

\def\titl{Performance Programming Coursework:
  Serial Optimization of a Molecual Dynamics Program}

\title{\titl}

\author{}

\ShortHeadings{B160509}{B160509}
\firstpageno{1}


\begin{document}

\maketitle

\begin{abstract}
\end{abstract}

\begin{keywords}
Scientific programming, serial optimization, molecular dynamics,
Fortran
\end{keywords}

\section{Introduction} % {{{
\label{sec:intro}

This paper documents the serial performance optimization conducted for
a molecular dynamics program written in the Fortran programming
language.
The program reads data from $n$ molecules as its input and iterates
a predefined amount of steps.
Each step the data of the molecules (e.g.\ force, position in a three
dimensional space, velocity) is updated.
The program counts collisions between molecules and writes the
data for each molecule of the simulation out at certain, also
predefined, intervals.
The original version of the program is not optimized for computational
efficiency.

This paper describes, documents and discusses the process of
optimizing the original version of the program serially.
The program was optimized for the Cirrus supercomputer, a tier-2
UK national supercomputer of the engineering and physical sciences
research council, which is hosted and maintained by the EPCC
\citep{cirrus}.
The compilers used were Intel's Fortran compiler \texttt{ifort},
version $18.0.5$ and $19.0.0$ for the linux operating system
\citep{ifort18, ifort19}.
The conducted optimizations range from choosing the appropriate
compiler flags over rewriting performance critical sections of the
program to hardware specific optimizations, like leveraging
vectorization and cache optimizations.
Since raw performance benefits are not all that is important for
writing well performing and good programs, the maintainability and
portability of the program are also looked at and discussed.

% TODO: hint on the results

This paper continues in Section~\ref{sec:md} with describing the
molecular dynamics program in detail.
Section~\ref{sec:setup} describes Cirrus and how the correctness of
the program is tested with a regression test suite.
Also the benchmark suite used for assessing the performance benefits
of an optimization is outlined.
Section~\ref{sec:opt} lists, describes and discusses all
optimizations tested with their performance benefits.
Afterwards, the results are discussed in Section~\ref{sec:dis}.
At least a conclusion is given in Section~\ref{sec:con}.
% }}}

\section{Molecular Dynamics Program} % {{{
\label{sec:md}

This section describes what the molecular dynamics program, which is
optimized, does.
The program is a simple molecular dynamics program.
It reads data from $n$ particles from a file.
In the following, subscripts $1 \leq i \leq n$ refer to a particle
of the simulation.
The data for a particle $i$ is its mass $m_i$, the viscosity of
a fluid $i$ is part of $vis_i$, the position of the particle's center
in a three dimensional space $\vec{p}_i$, which is relative to a large
central mass and its velocity $\vec{v}_i$.
The program iterates a predefined amount of iterations.
Each iteration represents a time step in the particle simulation.
The time is updated by a constant value $\Delta_t$.
Every step the position and the velocity of each particle is
updated, based on the gravitational forces operating on each particle.
The gravitational forces are the forces between each particle and the
gravitational force coming from the central mass.
The particles are part of a fluid, which means the viscosity of
the fluid must also be taken into account.
The last external force operating on a particle is wind $\vec{w}$,
which is a constant vector over the whole simulation.

The gravitational forces are computed based on Newton's law of
universal gravitation.
It states, that any two physical objects attract each other
with a force, which is proportional to the mass of both objects and
inversely proportional to the squared distance between both
\citep{feynman1963}.
The scalar gravitational force $F$ between two objects 1 and 2 can be
mathematically described as:
\begin{align}
  F_{1,2} = G\frac{m_1 m_2}{||\vec{p}_1 - \vec{p}_2||_2^2},
\end{align}
where $G$ is the gravitational constant, $m_i$ the mass of object $i$
and $||\vec{p}_1 - \vec{p}_2||_2$ the Euclidean or $L_2$ distance
between the centers of both objects.
The vector form of the gravitational force object 2 operates on object
1, which also accounts for the direction of the force, is given by:
\begin{align}
  \vec{F}_{1\leftarrow2} = -F_{1,2}\frac{\vec{p}_1 - \vec{p}_2}
                   {||\vec{p}_1 - \vec{p}_2||_2}
          = -G\frac{m_1 m_2 (\vec{p}_1 - \vec{p}_2)}
                   {||\vec{p}_1 - \vec{p}_2||_2^3}.
\end{align}
The gravitational force, which object 1 operates on object 2 is the
additive inverse of $\vec{F}_{1 \leftarrow 2}$:
$\vec{F}_{2 \leftarrow 1} = -\vec{F}_{1 \leftarrow 2}$.
If particles collide, the gravitational forces between the two object
are negated.
The program finds collisions, by checking if the distance of two
particles is smaller than a threshold $\tau_{1,2}$, which is the sum
of the radii of the two particles.
For the program, all particles have a radius of $\frac{1}{2}$, so the
threshold for a collision is $1$.
Now we can define a pairwise gravitational forces function for the
particles of the simulation as:
\begin{align}
  f_{1 \leftarrow 2} := \begin{cases}
    \vec{F}_{1 \leftarrow 2} &\text{if }
      ||\vec{p}_1 - \vec{p}_2||_2 \ge \tau_{1,2} \\
    -\vec{F}_{1 \leftarrow 2} &\text{otherwise}
  \end{cases}.
\end{align}
Other than the pairwise gravitational forces between the particles,
there is the gravitational force of the central mass
$\vec{F}_{1 \leftarrow central}$.
The central mass lies at the origin of the three dimensional space,
which means its position vector $\vec{p}_{central} = 0$.

The viscosity of the fluid is another force operating on a particle.
It is simply the negative of the viscosity of the fluid multiplied
by the velocity vector of particle $i: -vis_i \vec{v}_i$.
Shear velocity of the fluid is not taken into account.
Lastly, there is the wind force, which is simply the negated viscosity
of the fluid particle $i$ is part of multiplied by the wind vector:
$-vis_i \vec{w}$.
The overall force per iteration operating on particle $i$ can now
be described as:
\begin{align}
  \vec{F}_i = -vis_i(\vec{v}_i + \vec{w}) +
              \vec{F}_{i \leftarrow central} +
              \sum_{j\neq i}^n f_{i \leftarrow j}.
\end{align}
Based on $\vec{F}_i$ we can now update $\vec{p}_i$ and $\vec{v}_i$:
\begin{align}
  \vec{p}_i &= \vec{p}_i + \Delta_t \vec{v}_i \\
  \vec{v}_i &= \vec{v}_i + \Delta_t \frac{\vec{F}_i}{m_i}.
\end{align}
The iterations of the program are broken down into supersteps.
On completion of a superstep, the updated particles are exported to a
file with the same format as the input file.

% }}}

\section{Setup} % {{{
\label{sec:setup}

This section outlines the settings, under which the program was
optimized for performance. Information about the used hardware is
given.
The way correctness of the program was tested is described.
Lastly the settings and the criterion for the benchmark for the
assessment of the optimizations are shown.

Like stated in Section~\ref{sec:intro}, the program was optimized for
the Cirrus supercomputer \citep{cirrus}.
Since we are running the program serially, we are not concerned with
the amount of nodes or the interconnect, but will focus on a single
compute node.
A single compute node of Cirrus contains two 2.1 GHz, 18-core Intel
Xeon E5-2695 processors (code name: Broadwell).
The processor supports the AVX2 vector instruction set \citep{avx2}.
Each processor is connected to 128 Gigabyte of memory.
Both processors are within a NUMA region, so 256 Gigabyte of memory
are actually at ones disposal \citep{cirrus_hardware}.
The compute node offers three levels of cache:
\begin{enumerate}
  \item 32 Kilobyte instruction and 32 Kilobyte of data cache
        (per core)
  \item 256 Kilobyte (per core)
  \item 45 Megabyte (shared)
\end{enumerate}

Testing the correctness of the program is not as straight-forward as
it seems at first glance.
Like stated in Section~\ref{sec:md}, after each superstep, the
updated particles are written out to file.
Comparing the output of the optimized version of the program with the
original one would be a sufficient test for correctness, if it were
not for floating point rounding errors.
These accumulate and after a certain amount of time, the numbers
generated by the optimized version will be too different from the
original ones.

In order to avoid getting different results, just because of floating
point rounding errors, the original version of the code was augmented
by a special test setting.
This test setting differs from the normal program, because it reads
the data it has written out after a superstep back in.
That way, the next superstep will work with the floating point numbers
that are crippled by writing them to file.
The floating point numbers are written to file text based in
exponential form with 16 digits, eight digits on the right side of the
decimal point \citep[see e.g.][for formatting io in Fortran]
{fortran_formats}.
Changing the output format to a more precise representation is not
possible, because this would mean the files generated as output would
not have the same format as the input file with the initial states of
the particles.
The optimized version of the program has the exact same test setting.
This allows for effectively comparing the output files of both
versions, because floating point rounding errors now only accumulate
over a single superstep.

Once the discrepancy between the output values of the optimized
version and the original one surpasses a predefined error level,
the optimization is deemed to result in an incorrect version of the
program.
The predefined error level was set to be $0.05$.
If any output file contains a \texttt{NaN} value, the program is
also deemed incorrect.
The regression test suite was implemented with a Python script.

The program runs five supersteps.
Each superstep encompasses 100 iterations.
The input file which was used contained 4096 particles.
Computation was done using double precision floats.
The goal of the optimization process was to reduce the wall-clock
time of the program to a minimum, while bearing in mind portability
and more importantly maintainability.
The program measures the time it needs for each superstep and its
overall time, including the file output.
In order to build the benchmark suite around the program, the timings
are exported to another file when the program has finished the
simulation.
The program was tested by running it ten times on a compute node of
Cirrus and taking the average from those ten runs as the performance
measurement.
Running it ten times is more than enough to get a stable average,
because running the program as a job on a compute node of Cirrus
means exclusive hardware access to that node.
Only IO performance can be influenced by other users, because Cirrus
uses Lustre for its file system which is shared
\citep{cirrus_hardware}.
As will be discussed below, IO performance is actually negligible when
it comes to performance optimization when compared to the
computational effort of the simulation.

% }}}

\section{Optimizations} % {{{
\label{sec:opt}

This section documents the process of performance optimization of the
program.
Focus lies more on the process, not the results.
All the successively performed optimizations are described.
Code quality in form of readability, portability and maintainability
is taken into account during the whole process and the optimizations
are all looked at from this perspective.
The optimization process can basically broken down into four phases:
(\romannumeral 1) restructuring the source code without changing
the critical section,
(\romannumeral 2) trying out compiler flags, (\romannumeral 3)
rewriting the program for better performance and (\romannumeral 4)
trying compiler flags on the rewritten version of the program again.

% continue here 1st phase


% journey through time

% discuss every thought I had

% use pseudo code and small fortran snippets for visualization

% make it clear that I could use common sense most of the time,
% but include vtune results and io time

% checkpoints: 1. flags, 2. rewriting 3. flags again

% }}}

\section{Discussion} % {{{
\label{sec:dis}

% }}}

\section{Conclusion} % {{{
\label{sec:con}

% }}}

\bibliography{library.bib}

\end{document}
